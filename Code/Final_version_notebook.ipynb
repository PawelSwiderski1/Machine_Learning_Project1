{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6998,
     "status": "ok",
     "timestamp": 1681936609183,
     "user": {
      "displayName": "Paweł Świderski",
      "userId": "16606458260379333856"
     },
     "user_tz": -120
    },
    "id": "EAdjPzkKB_fz",
    "outputId": "aefa3ab5-e7ae-4d30-b46d-749c43a3b48e"
   },
   "outputs": [],
   "source": [
    "\n",
    "#!pip install fast_ml \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pobieranie paczek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nZ5lMyv-z0dw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from fast_ml.utilities import display_all\n",
    "from fast_ml.feature_selection import get_duplicate_features\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed = 42\n",
    "from sklearn import preprocessing\n",
    "from fast_ml.feature_selection import get_constant_features\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, accuracy_score, classification_report, roc_auc_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pobranie zbioru z danymi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2006,
     "status": "ok",
     "timestamp": 1681936613328,
     "user": {
      "displayName": "Paweł Świderski",
      "userId": "16606458260379333856"
     },
     "user_tz": -120
    },
    "id": "lrd28T-0z0dz",
    "outputId": "cbefe830-aa1e-457c-d2f6-eaffb23d362a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozmiar ramki:  (50000, 301)\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('dataset_1.csv')\n",
    "print(\"Rozmiar ramki: \", df1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdźmy czy w ramce są wartości Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W ramce nie mamy żadnych wartości Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('int64'), dtype('float64')], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W ramce mamy tylko wartości typu int oraz float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oddzielenie zmiennej przewidywanej 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "V2TxM7khfYvW"
   },
   "outputs": [],
   "source": [
    "y = np.array(df1['target'])\n",
    "X = df1.drop(['target'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdźmy rozkład przewidywanej zmiennej 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozkład w całej ramce:  {0: 48009, 1: 1991}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(\"Rozkład w całej ramce: \", dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rozkład jest bardzo nie równy zatem przy dzieleniu na zbiory test, train i val użyjemy stratify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NeidFPodkAto"
   },
   "source": [
    "Podział na zbiory test, train i val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wsU4jHNlk6M0"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.3, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_val, y_val, stratify=y_val, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1681936613578,
     "user": {
      "displayName": "Paweł Świderski",
      "userId": "16606458260379333856"
     },
     "user_tz": -120
    },
    "id": "8dT3Vu6RHxFq",
    "outputId": "63b55195-bad4-4555-8085-411571299a89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35000, 300)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PdAeVLEEf3LU"
   },
   "source": [
    "Tworzymy ramke, która jest kopią X_train, na której będziemy wykonywać różne procedury processingu danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VAMss9RxFyBe"
   },
   "outputs": [],
   "source": [
    "X_train_processing = X_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFFqDqq_gPyk"
   },
   "source": [
    "Zaczniemy od usunięcia kolumn ze stałymi wartościami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-gEzaR-6z0d5"
   },
   "outputs": [],
   "source": [
    "constant_features = get_constant_features(X_train_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1681936614604,
     "user": {
      "displayName": "Paweł Świderski",
      "userId": "16606458260379333856"
     },
     "user_tz": -120
    },
    "id": "d9byrL_1UJQb",
    "outputId": "d4499504-c88b-4aa9-c85a-21adafcf44bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['var_167', 'var_158', 'var_113', 'var_112', 'var_201', 'var_248', 'var_44', 'var_99', 'var_97', 'var_212', 'var_215', 'var_92', 'var_89', 'var_61', 'var_227', 'var_87', 'var_66', 'var_67', 'var_225', 'var_69', 'var_81', 'var_196', 'var_33', 'var_195', 'var_287', 'var_297', 'var_294', 'var_171', 'var_178', 'var_180', 'var_135', 'var_182', 'var_120', 'var_14', 'var_23', 'var_129', 'var_127', 'var_122', 'var_80']\n"
     ]
    }
   ],
   "source": [
    "constant_features_list = constant_features.query(\"Desc=='Constant'\")['Var'].to_list()\n",
    "print(constant_features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1681936614604,
     "user": {
      "displayName": "Paweł Świderski",
      "userId": "16606458260379333856"
     },
     "user_tz": -120
    },
    "id": "IO0_Bim_UJQb",
    "outputId": "5cc64809-6110-4b5d-d53b-0067f0601f4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozmiar ramki przed usunięciem stałych kolumn:  (35000, 300)\n",
      "Rozmiar ramki po usunięciu stałych kolumn:  (35000, 261)\n"
     ]
    }
   ],
   "source": [
    "print('Rozmiar ramki przed usunięciem stałych kolumn: ', X_train_processing.shape)\n",
    "X_train_processing.drop(columns = constant_features_list, inplace=True)\n",
    "print('Rozmiar ramki po usunięciu stałych kolumn: ', X_train_processing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "a8osAG7Czm7z"
   },
   "outputs": [],
   "source": [
    "def drop_constant_features(df):\n",
    "  constant_features = get_constant_features(df)\n",
    "  constant_features_list = constant_features.query(\"Desc=='Constant'\")['Var'].to_list()\n",
    "  df.drop(columns = constant_features_list, inplace=True)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFgNxl09ChzA"
   },
   "source": [
    "Zajmiemy się też usunięciem \"prawie stałych\" kolumn, ustawiony threshold jest na tyle wysoki, że usuwamy jedynie kolumny które mają dosłownie kilka odmiennych wartości. Małe ryzyko utraty informacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "feq0KLCVUJQc"
   },
   "outputs": [],
   "source": [
    "constant_features = get_constant_features(X_train_processing, threshold=0.9999, dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1681936614606,
     "user": {
      "displayName": "Paweł Świderski",
      "userId": "16606458260379333856"
     },
     "user_tz": -120
    },
    "id": "6nTZYKWpUJQc",
    "outputId": "41da64e8-0266-4294-9ab0-a7ce803f3060"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['var_2', 'var_36', 'var_133', 'var_124', 'var_104', 'var_73', 'var_223', 'var_170', 'var_183', 'var_34', 'var_234', 'var_243', 'var_247', 'var_280', 'var_283', 'var_233', 'var_217', 'var_210', 'var_285', 'var_189', 'var_187', 'var_228', 'var_150', 'var_153', 'var_151', 'var_10', 'var_11', 'var_12', 'var_28', 'var_65', 'var_72', 'var_111', 'var_141', 'var_6', 'var_71', 'var_116', 'var_265', 'var_9', 'var_7', 'var_289']\n"
     ]
    }
   ],
   "source": [
    "quasi_constant_features_list = constant_features.query(\"Desc=='Quasi Constant'\")['Var'].to_list()\n",
    "print(quasi_constant_features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5tzARt4UJQd"
   },
   "source": [
    "Jak widać jest ich całkiem sporo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1681936614606,
     "user": {
      "displayName": "Paweł Świderski",
      "userId": "16606458260379333856"
     },
     "user_tz": -120
    },
    "id": "ftojSkL9UJQd",
    "outputId": "84467dfe-cd90-4978-d522-81f83e847212"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozmiar ramki przed usunięciem \"prawie stałych\" kolumn:   (35000, 261)\n",
      "Rozmiar ramki po usunięciu \"prawie stałych\" kolumn:  (35000, 221)\n"
     ]
    }
   ],
   "source": [
    "print('Rozmiar ramki przed usunięciem \"prawie stałych\" kolumn:  ', X_train_processing.shape)\n",
    "X_train_processing.drop(columns = quasi_constant_features_list, inplace=True)\n",
    "print('Rozmiar ramki po usunięciu \"prawie stałych\" kolumn: ', X_train_processing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "M6mSctXizprl"
   },
   "outputs": [],
   "source": [
    "def drop_quasi_constant_features(df):\n",
    "  quasi_constant_features = get_constant_features(X_train, threshold=0.9999, dropna=False)\n",
    "  quasi_constant_features_list = quasi_constant_features.query(\"Desc=='Quasi Constant'\")['Var'].to_list()\n",
    "  df.drop(columns = quasi_constant_features_list, inplace=True)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "psYBuZ_4Cuu1"
   },
   "source": [
    "Usunięcie zduplikowanych kolumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "u2bVCZWlz0d4"
   },
   "outputs": [],
   "source": [
    "duplicate_features = get_duplicate_features(X_train_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1681936672311,
     "user": {
      "displayName": "Paweł Świderski",
      "userId": "16606458260379333856"
     },
     "user_tz": -120
    },
    "id": "85fITyYpz0d4",
    "outputId": "45f5186c-0bbf-4a3c-97f0-1e1808ba9cbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['var_239', 'var_148', 'var_269', 'var_232', 'var_106', 'var_216', 'var_263', 'var_250', 'var_199', 'var_296']\n"
     ]
    }
   ],
   "source": [
    "duplicate_features_list = duplicate_features.query(\"Desc=='Duplicate Values'\")['feature2'].to_list()\n",
    "print(duplicate_features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1681936672312,
     "user": {
      "displayName": "Paweł Świderski",
      "userId": "16606458260379333856"
     },
     "user_tz": -120
    },
    "id": "d78f7inT9bHo",
    "outputId": "81502750-9c98-4ca7-b464-8d5f7b1a8d52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozmiar ramki przed usunięciem zduplikowanych kolumn:   (35000, 221)\n",
      "Rozmiar ramki po usunięciu zduplikowanych kolumn:  (35000, 211)\n"
     ]
    }
   ],
   "source": [
    "print('Rozmiar ramki przed usunięciem zduplikowanych kolumn:  ', X_train_processing.shape)\n",
    "X_train_processing.drop(columns = duplicate_features_list, inplace = True)\n",
    "print('Rozmiar ramki po usunięciu zduplikowanych kolumn: ', X_train_processing.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "MRKOzcuE0AKA"
   },
   "outputs": [],
   "source": [
    "def drop_duplicates(df):\n",
    "  duplicate_features = get_duplicate_features(df)\n",
    "  duplicate_features_list = duplicate_features.query(\"Desc=='Duplicate Values'\")['feature2'].to_list()\n",
    "  df.drop(columns = duplicate_features_list, inplace = True)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hlQ1qoSupU8R"
   },
   "source": [
    "Outliery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1381,
     "status": "ok",
     "timestamp": 1681936673690,
     "user": {
      "displayName": "Paweł Świderski",
      "userId": "16606458260379333856"
     },
     "user_tz": -120
    },
    "id": "uQX6R3zbrMGO",
    "outputId": "4fc29dfd-3234-4cac-d80a-ac9d7ea0c814"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_1        16\n",
      "var_2         1\n",
      "var_3        16\n",
      "var_4      2863\n",
      "var_5       193\n",
      "           ... \n",
      "var_296     841\n",
      "var_297       0\n",
      "var_298      63\n",
      "var_299      25\n",
      "var_300    1341\n",
      "Length: 300, dtype: int64\n",
      "W sumie wszystkich outlierów jest:  326676\n"
     ]
    }
   ],
   "source": [
    "Q1 = X_train.quantile(0.25)\n",
    "Q3 = X_train.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(((X_train < (Q1 - 1.5 * IQR)) | (X_train > (Q3 + 1.5 * IQR))).sum())\n",
    "print(\"W sumie wszystkich outlierów jest: \", ((X_train < (Q1 - 1.5 * IQR)) | (X_train > (Q3 + 1.5 * IQR))).sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLSRZLetrMyy"
   },
   "source": [
    "Spróbujemy dobrać inne granice klasyfikacji outlierów i zobaczyć czy nadal jest ich tak dużo. Zmieńmy współczynnik przy IQR nas 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1193,
     "status": "ok",
     "timestamp": 1681936674881,
     "user": {
      "displayName": "Paweł Świderski",
      "userId": "16606458260379333856"
     },
     "user_tz": -120
    },
    "id": "zVmpTJJOrQCd",
    "outputId": "f98beccd-cffd-425b-8bf4-478e67a3a15f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_1        16\n",
      "var_2         1\n",
      "var_3        16\n",
      "var_4       775\n",
      "var_5       193\n",
      "           ... \n",
      "var_296     841\n",
      "var_297       0\n",
      "var_298      63\n",
      "var_299      25\n",
      "var_300    1341\n",
      "Length: 300, dtype: int64\n",
      "W sumie wszystkich outlierów jest:  309035\n"
     ]
    }
   ],
   "source": [
    "Q1 = X_train.quantile(0.25)\n",
    "Q3 = X_train.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(((X_train < (Q1 - 2.5 * IQR)) | (X_train > (Q3 + 2.5 * IQR))).sum())\n",
    "print(\"W sumie wszystkich outlierów jest: \", ((X_train < (Q1 - 2.5 * IQR)) | (X_train > (Q3 + 2.5 * IQR))).sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5frMC27UJQh"
   },
   "source": [
    "Nadal outlierów jest bardzo dużo, dlatego usuwanie nie wchodzi w grę. Zatem zaminimy dolny oraz górny centyl wartości medianą"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_numerical_outliers(df, z_thresh=3):\n",
    "    for col in df:\n",
    "        median = df[col].median()\n",
    "        outliers = (df[col] > df[col].quantile(.99)) | (df[col] < df[col].quantile(.01))\n",
    "        df[col][outliers]=np.nan\n",
    "        df.replace({np.nan:median}, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_13</th>\n",
       "      <th>var_15</th>\n",
       "      <th>var_16</th>\n",
       "      <th>var_17</th>\n",
       "      <th>var_18</th>\n",
       "      <th>...</th>\n",
       "      <th>var_286</th>\n",
       "      <th>var_288</th>\n",
       "      <th>var_290</th>\n",
       "      <th>var_291</th>\n",
       "      <th>var_292</th>\n",
       "      <th>var_293</th>\n",
       "      <th>var_295</th>\n",
       "      <th>var_298</th>\n",
       "      <th>var_299</th>\n",
       "      <th>var_300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13889</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18173</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11779</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28068</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26232</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28062</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44991</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42528</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31683</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>891.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47738</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35000 rows × 211 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var_1  var_3  var_4  var_5  var_8  var_13  var_15  var_16  var_17  \\\n",
       "13889    0.0    0.0   2.88    0.0      0     0.0     3.0     0.0    0.00   \n",
       "18173    0.0    0.0   2.91    0.0      0     0.0     3.0     0.0    0.00   \n",
       "11779    0.0    0.0   2.82    0.0      0     0.0     3.0     0.0   14.25   \n",
       "28068    0.0    0.0   5.82    0.0      0     0.0     3.0     0.0    0.00   \n",
       "26232    0.0    0.0   0.00    0.0      0     0.0     0.0     0.0    0.00   \n",
       "...      ...    ...    ...    ...    ...     ...     ...     ...     ...   \n",
       "28062    0.0    0.0  11.04    0.0      0     0.0     0.0     0.0    5.82   \n",
       "44991    0.0    0.0   5.70    0.0      0     0.0     3.0     0.0    0.00   \n",
       "42528    0.0    0.0   0.00    0.0      0     0.0     0.0     0.0    5.82   \n",
       "31683    0.0    0.0   8.73    0.0      0     0.0     3.0     0.0    0.00   \n",
       "47738    0.0    0.0   2.82    0.0      0     0.0     3.0     0.0    0.00   \n",
       "\n",
       "       var_18  ...  var_286  var_288  var_290  var_291  var_292  var_293  \\\n",
       "13889     0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "18173     0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "11779     0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "28068     0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "26232     0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "...       ...  ...      ...      ...      ...      ...      ...      ...   \n",
       "28062     0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "44991     0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "42528     0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "31683     0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "47738     0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "       var_295  var_298  var_299  var_300  \n",
       "13889      0.0      0.0      0.0     0.00  \n",
       "18173      0.0      0.0      0.0     0.00  \n",
       "11779      0.0      0.0      0.0     0.00  \n",
       "28068      0.0      0.0      0.0     0.00  \n",
       "26232      0.0      0.0      0.0     0.00  \n",
       "...        ...      ...      ...      ...  \n",
       "28062      0.0      0.0      0.0     0.00  \n",
       "44991      0.0      0.0      0.0     0.00  \n",
       "42528      0.0      0.0      0.0     0.00  \n",
       "31683      3.0      0.0      0.0   891.36  \n",
       "47738      0.0      0.0      0.0     0.00  \n",
       "\n",
       "[35000 rows x 211 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_processing = replace_numerical_outliers(X_train_processing)\n",
    "X_train_processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po zamianie na medianę powstało dużo nowych kolumn, które mają same zera. Jeszcze raz zatem usuniemy stałe kolumny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozmiar ramki przed usunięciem stałych kolumn:  (35000, 211)\n",
      "Rozmiar ramki po usunięciu stałych kolumn:  (35000, 121)\n"
     ]
    }
   ],
   "source": [
    "print('Rozmiar ramki przed usunięciem stałych kolumn: ', X_train_processing.shape)\n",
    "X_train_processing = drop_constant_features(X_train_processing)\n",
    "print('Rozmiar ramki po usunięciu stałych kolumn: ', X_train_processing.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peROdNhbnv3S"
   },
   "source": [
    "Przejdziemy teraz do metod dalszego usuwania kolumn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKq3jWwIth81"
   },
   "source": [
    "Usuwanie (jednej z) kolumn, których współczynnik korelacji spearmana jest większy niż 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_drop(df):\n",
    "  corr_matrix = df.corr('spearman')\n",
    "\n",
    "  n = df.shape[1]\n",
    "  threshold = 0.90\n",
    "  var_to_drop = []\n",
    "  for j in range(n):\n",
    "    for i in range(j):\n",
    "      if corr_matrix.iloc[i][j] >= threshold:\n",
    "        var_to_drop.append(corr_matrix.index[i])\n",
    "  \n",
    "  var_to_drop = set(var_to_drop)\n",
    "  var_to_drop = list(var_to_drop)\n",
    "  print(\"liczba kolumn które usuwamy:\" ,len(var_to_drop))\n",
    "  print(\"lista kolumn, które usuwamy:\", var_to_drop)\n",
    "\n",
    "  df = df.drop(var_to_drop, axis = 1)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1681936691436,
     "user": {
      "displayName": "Paweł Świderski",
      "userId": "16606458260379333856"
     },
     "user_tz": -120
    },
    "id": "kwP3t9DuuZVz",
    "outputId": "6fa35437-0b58-4b2c-8022-8e3950d311c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liczba kolumn które usuwamy: 53\n",
      "lista kolumn, które usuwamy: ['var_18', 'var_140', 'var_31', 'var_47', 'var_82', 'var_38', 'var_8', 'var_21', 'var_105', 'var_96', 'var_37', 'var_186', 'var_144', 'var_70', 'var_109', 'var_118', 'var_62', 'var_100', 'var_152', 'var_57', 'var_30', 'var_226', 'var_284', 'var_103', 'var_51', 'var_41', 'var_4', 'var_155', 'var_123', 'var_168', 'var_131', 'var_93', 'var_175', 'var_220', 'var_55', 'var_206', 'var_83', 'var_117', 'var_121', 'var_88', 'var_143', 'var_229', 'var_176', 'var_166', 'var_58', 'var_162', 'var_91', 'var_174', 'var_164', 'var_52', 'var_19', 'var_203', 'var_160']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_15</th>\n",
       "      <th>var_17</th>\n",
       "      <th>var_29</th>\n",
       "      <th>var_35</th>\n",
       "      <th>var_46</th>\n",
       "      <th>var_49</th>\n",
       "      <th>var_50</th>\n",
       "      <th>var_54</th>\n",
       "      <th>var_64</th>\n",
       "      <th>var_74</th>\n",
       "      <th>...</th>\n",
       "      <th>var_272</th>\n",
       "      <th>var_275</th>\n",
       "      <th>var_276</th>\n",
       "      <th>var_277</th>\n",
       "      <th>var_279</th>\n",
       "      <th>var_281</th>\n",
       "      <th>var_288</th>\n",
       "      <th>var_292</th>\n",
       "      <th>var_295</th>\n",
       "      <th>var_300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35000.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.993971</td>\n",
       "      <td>0.961346</td>\n",
       "      <td>1.955717</td>\n",
       "      <td>8995.286265</td>\n",
       "      <td>104663.119482</td>\n",
       "      <td>40.164371</td>\n",
       "      <td>3.067719</td>\n",
       "      <td>0.010429</td>\n",
       "      <td>1713.967004</td>\n",
       "      <td>1.590886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.792747</td>\n",
       "      <td>0.024971</td>\n",
       "      <td>82.269169</td>\n",
       "      <td>1.432810</td>\n",
       "      <td>2.014221</td>\n",
       "      <td>0.011086</td>\n",
       "      <td>0.035178</td>\n",
       "      <td>0.008306</td>\n",
       "      <td>0.127714</td>\n",
       "      <td>2046.161966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.416351</td>\n",
       "      <td>2.467787</td>\n",
       "      <td>0.510095</td>\n",
       "      <td>35907.614867</td>\n",
       "      <td>56806.301485</td>\n",
       "      <td>47.282043</td>\n",
       "      <td>6.771094</td>\n",
       "      <td>0.101588</td>\n",
       "      <td>11541.361699</td>\n",
       "      <td>0.711526</td>\n",
       "      <td>...</td>\n",
       "      <td>3.003194</td>\n",
       "      <td>0.156040</td>\n",
       "      <td>522.019328</td>\n",
       "      <td>5.234437</td>\n",
       "      <td>6.866269</td>\n",
       "      <td>0.104705</td>\n",
       "      <td>0.314429</td>\n",
       "      <td>0.152159</td>\n",
       "      <td>0.605675</td>\n",
       "      <td>15078.432648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.820000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24784.964400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.860000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66240.978300</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.920000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>101680.519800</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.960000</td>\n",
       "      <td>159.297900</td>\n",
       "      <td>116137.869226</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>2.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>14.850000</td>\n",
       "      <td>10.670000</td>\n",
       "      <td>285773.062500</td>\n",
       "      <td>429816.927000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>47.520000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>137496.787200</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>25.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7948.800000</td>\n",
       "      <td>43.200000</td>\n",
       "      <td>53.010000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.970000</td>\n",
       "      <td>2.850000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>193611.974400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             var_15        var_17        var_29         var_35         var_46  \\\n",
       "count  35000.000000  35000.000000  35000.000000   35000.000000   35000.000000   \n",
       "mean       1.993971      0.961346      1.955717    8995.286265  104663.119482   \n",
       "std        1.416351      2.467787      0.510095   35907.614867   56806.301485   \n",
       "min        0.000000      0.000000      1.820000       0.000000   24784.964400   \n",
       "25%        0.000000      0.000000      1.860000       0.000000   66240.978300   \n",
       "50%        3.000000      0.000000      1.920000       3.000000  101680.519800   \n",
       "75%        3.000000      0.000000      1.960000     159.297900  116137.869226   \n",
       "max        3.000000     14.850000     10.670000  285773.062500  429816.927000   \n",
       "\n",
       "             var_49        var_50        var_54         var_64        var_74  \\\n",
       "count  35000.000000  35000.000000  35000.000000   35000.000000  35000.000000   \n",
       "mean      40.164371      3.067719      0.010429    1713.967004      1.590886   \n",
       "std       47.282043      6.771094      0.101588   11541.361699      0.711526   \n",
       "min        1.000000      0.000000      0.000000       0.000000      0.000000   \n",
       "25%        2.000000      0.000000      0.000000       0.000000      1.000000   \n",
       "50%        3.000000      0.000000      0.000000       0.000000      2.000000   \n",
       "75%       99.000000      2.880000      0.000000       0.000000      2.000000   \n",
       "max       99.000000     47.520000      1.000000  137496.787200      2.000000   \n",
       "\n",
       "       ...       var_272       var_275       var_276       var_277  \\\n",
       "count  ...  35000.000000  35000.000000  35000.000000  35000.000000   \n",
       "mean   ...      0.792747      0.024971     82.269169      1.432810   \n",
       "std    ...      3.003194      0.156040    522.019328      5.234437   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "max    ...     25.920000      1.000000   7948.800000     43.200000   \n",
       "\n",
       "            var_279       var_281       var_288       var_292       var_295  \\\n",
       "count  35000.000000  35000.000000  35000.000000  35000.000000  35000.000000   \n",
       "mean       2.014221      0.011086      0.035178      0.008306      0.127714   \n",
       "std        6.866269      0.104705      0.314429      0.152159      0.605675   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       53.010000      1.000000      2.970000      2.850000      3.000000   \n",
       "\n",
       "             var_300  \n",
       "count   35000.000000  \n",
       "mean     2046.161966  \n",
       "std     15078.432648  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max    193611.974400  \n",
       "\n",
       "[8 rows x 68 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_processing = correlation_drop(X_train_processing)\n",
    "X_train_processing.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To kończy nasz podstawowy preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train_processing)\n",
    "X_test = X_test[X_test.columns.intersection(X_train.columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jako dodatkową opcję zmniejszenie liczby kolumn użyjemy Recursive Feature Elimination (RFE), która wybiera kolumny są najbardziej znaczące w przewidywaniu zmiennej target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['var_17', 'var_29', 'var_35', 'var_46', 'var_50', 'var_74', 'var_75',\n",
      "       'var_76', 'var_110', 'var_145', 'var_157', 'var_161', 'var_173',\n",
      "       'var_185', 'var_190', 'var_207', 'var_222', 'var_231', 'var_262',\n",
      "       'var_279'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfe = RFE(estimator=rfc, n_features_to_select = 20)\n",
    "rfe.fit_transform(X_train_processing, y_train)\n",
    "selected_features = X_train_processing.columns[rfe.support_]\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zapiszemy wyniki w oddzielnych ramkach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe = X_train[selected_features]\n",
    "X_test_rfe = X_test[X_test.columns.intersection(X_train_rfe.columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przechodzimy do Modeli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdźmy jak rozkłada się zmienna target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1681936613329,
     "user": {
      "displayName": "Paweł Świderski",
      "userId": "16606458260379333856"
     },
     "user_tz": -120
    },
    "id": "29iheN5_jViy",
    "outputId": "3a9619d2-8f9f-4c83-977a-2533bbc04270"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozkład w całej ramce:  {0: 48009, 1: 1991}\n",
      "Rozkład w zbiorze testowym:  {0: 4321, 1: 179}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(\"Rozkład w całej ramce: \", dict(zip(unique, counts)))\n",
    "\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "print(\"Rozkład w zbiorze testowym: \", dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Widzimy, że wartości 1 jest bardzo mało w porównaniu do wartości 0, w zbiorze testowym jest jedynie 179 wartości 1, co będzie prowadziło do problemów z uzyskaniem wysokiej precyzji.\n",
    "Uważamy, że tak samo dużą, jak nie większą, uwagę powinniśmy przywiązywąć do wyników cross-validacji, gdyż w tym przypadku może być ona bardziej miarodajna "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfESZR61tJm1"
   },
   "source": [
    "####  Logistyczna regresja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "vec09-olKiUr"
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "lr_model = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcZIAA81tXoX"
   },
   "source": [
    "Base preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6605,
     "status": "ok",
     "timestamp": 1681936980541,
     "user": {
      "displayName": "Paweł Świderski",
      "userId": "16606458260379333856"
     },
     "user_tz": -120
    },
    "id": "3KXIBekeXyVn",
    "outputId": "79844b45-bcde-4699-d974-12b20db542ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      4321\n",
      "           1       0.00      0.00      0.00       179\n",
      "\n",
      "    accuracy                           0.95      4500\n",
      "   macro avg       0.48      0.49      0.49      4500\n",
      "weighted avg       0.92      0.95      0.94      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "InMQmgvQt7LA"
   },
   "source": [
    "Preprocessing RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1928,
     "status": "ok",
     "timestamp": 1681936770112,
     "user": {
      "displayName": "Paweł Świderski",
      "userId": "16606458260379333856"
     },
     "user_tz": -120
    },
    "id": "iLAe497euAwJ",
    "outputId": "797f3e14-3253-4822-e771-01e6c4f8bc2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      4321\n",
      "           1       0.00      0.00      0.00       179\n",
      "\n",
      "    accuracy                           0.96      4500\n",
      "   macro avg       0.48      0.50      0.49      4500\n",
      "weighted avg       0.92      0.96      0.94      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_model.fit(X_train_rfe, y_train)\n",
    "\n",
    "y_pred = lr_model.predict(X_test_rfe)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać regresja logistyczna działa bardzo słabo gdyż przewiduje same 0, dlatego porzucimy szybko ten model i nie będziemy tracić czasu na cross-validacje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95      4321\n",
      "           1       0.13      0.22      0.16       179\n",
      "\n",
      "    accuracy                           0.91      4500\n",
      "   macro avg       0.55      0.58      0.56      4500\n",
      "weighted avg       0.93      0.91      0.92      4500\n",
      "\n",
      "Wynik ROC-AUC na zbiorze testowym:  0.5782743493837423\n",
      "Wynik ROC-AUC przez cross-validation:  0.5509427913040436\n",
      "Wynik F1 przez cross-validation:  0.13228550143053952\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_probs = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#Raport z wskaźnikami oceny modelu\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(\"Wynik ROC-AUC na zbiorze testowym: \", roc_auc_score(y_test, y_pred_probs))\n",
    "\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5, scoring=\"roc_auc\").mean()\n",
    "print(\"Wynik ROC-AUC przez cross-validation: \", scores)\n",
    "\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5, scoring=\"f1\").mean()\n",
    "print(\"Wynik F1 przez cross-validation: \", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95      4321\n",
      "           1       0.12      0.19      0.15       179\n",
      "\n",
      "    accuracy                           0.91      4500\n",
      "   macro avg       0.54      0.57      0.55      4500\n",
      "weighted avg       0.93      0.91      0.92      4500\n",
      "\n",
      "Wynik ROC-AUC na zbiorze testowym:  0.5670850038592866\n",
      "Wynik ROC-AUC przez cross-validation:  0.554548303627131\n",
      "Wynik F1 przez cross-validation:  0.13845906663508853\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train_rfe, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_rfe)\n",
    "y_pred_probs = clf.predict_proba(X_test_rfe)[:, 1]\n",
    "\n",
    "#Raport z wskaźnikami oceny modelu\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(\"Wynik ROC-AUC na zbiorze testowym: \", roc_auc_score(y_test, y_pred_probs))\n",
    "\n",
    "scores = cross_val_score(clf, X_train_rfe, y_train, cv=5, scoring=\"roc_auc\").mean()\n",
    "print(\"Wynik ROC-AUC przez cross-validation: \", scores)\n",
    "\n",
    "scores = cross_val_score(clf, X_train_rfe, y_train, cv=5, scoring=\"f1\").mean()\n",
    "print(\"Wynik F1 przez cross-validation: \", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uzyskaliśmy lepsze wyniki niż w regresji logistycznej, gdyż mamy precyzję jedynek w okolicy 0.12 oraz wynik F1 jest wysoki w porównaniu do innych modeli jednak wynik ROC-AUC jest słaby zarówno na zbiorze testowym jaki przy cross-validacji. Preprocessing RFE miał marginalny wpływ na wyniki."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      4321\n",
      "           1       0.17      0.01      0.02       179\n",
      "\n",
      "    accuracy                           0.96      4500\n",
      "   macro avg       0.56      0.50      0.50      4500\n",
      "weighted avg       0.93      0.96      0.94      4500\n",
      "\n",
      "Wynik ROC-AUC na zbiorze testowym:  0.8297007339755567\n",
      "Wynik ROC-AUC przez cross-validation:  0.7965584976780726\n",
      "Wynik F1 przez cross-validation:  0.01383803101492854\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_probs = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#Raport z wskaźnikami oceny modelu\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(\"Wynik ROC-AUC na zbiorze testowym: \", roc_auc_score(y_test, y_pred_probs))\n",
    "\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5, scoring=\"roc_auc\").mean()\n",
    "print(\"Wynik ROC-AUC przez cross-validation: \", scores)\n",
    "\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5, scoring=\"f1\").mean()\n",
    "print(\"Wynik F1 przez cross-validation: \", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      4321\n",
      "           1       0.24      0.02      0.04       179\n",
      "\n",
      "    accuracy                           0.96      4500\n",
      "   macro avg       0.60      0.51      0.51      4500\n",
      "weighted avg       0.93      0.96      0.94      4500\n",
      "\n",
      "Wynik ROC-AUC na zbiorze testowym:  0.8309684159082771\n",
      "Wynik ROC-AUC przez cross-validation:  0.7945318825003485\n",
      "Wynik F1 przez cross-validation:  0.0165142280191381\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train_rfe, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_rfe)\n",
    "y_pred_probs = clf.predict_proba(X_test_rfe)[:, 1]\n",
    "\n",
    "#Raport z wskaźnikami oceny modelu\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Wynik ROC-AUC na zbiorze testowym: \", roc_auc_score(y_test, y_pred_probs))\n",
    "\n",
    "scores = cross_val_score(clf, X_train_rfe, y_train, cv=5, scoring=\"roc_auc\").mean()\n",
    "print(\"Wynik ROC-AUC przez cross-validation: \", scores)\n",
    "\n",
    "scores = cross_val_score(clf, X_train_rfe, y_train, cv=5, scoring=\"f1\").mean()\n",
    "print(\"Wynik F1 przez cross-validation: \", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost spisuje się bardzo dobrze pod względem ROC-AUC, jest on wysoki zarówno na zbiorze testowym jaki przy cross-validacji, a do tego precision na preprocessing RFE podskoczyło do 0.24 jednak F1 jest bardzo niski, zdecydowanie niższy niż przy Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy spojrzeć też na znaczenie poszczególnych kolumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_importance(clf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy spojrzeć co się stanie jeśli usuniemy 2 kolumny o najmniejszym znaczeniu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      4321\n",
      "           1       0.10      0.01      0.01       179\n",
      "\n",
      "    accuracy                           0.96      4500\n",
      "   macro avg       0.53      0.50      0.49      4500\n",
      "weighted avg       0.93      0.96      0.94      4500\n",
      "\n",
      "Wynik ROC-AUC na zbiorze testowym:  0.8229162761051328\n",
      "Wynik ROC-AUC przez cross-validation:  [0.80898168 0.7715631  0.80239009 0.7975777  0.7810815 ]\n",
      "Wynik F1 przez cross-validation:  [0.02076125 0.01369863 0.02061856 0.01384083 0.01365188]\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train_rfe.drop(['var_49', 'var_262'], axis=1), y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_rfe.drop(['var_49', 'var_262'], axis=1))\n",
    "y_pred_probs = clf.predict_proba(X_test_rfe.drop(['var_49', 'var_262'], axis=1))[:, 1]\n",
    "\n",
    "#Raport z wskaźnikami oceny modelu\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(\"Wynik ROC-AUC na zbiorze testowym: \", roc_auc_score(y_test, y_pred_probs))\n",
    "\n",
    "scores = cross_val_score(clf, X_train_rfe.drop(['var_49', 'var_262'], axis=1), y_train, cv=5, scoring=\"roc_auc\")\n",
    "print(\"Wynik ROC-AUC przez cross-validation: \", scores)\n",
    "\n",
    "scores = cross_val_score(clf, X_train_rfe, y_train, cv=5, scoring=\"f1\")\n",
    "print(\"Wynik F1 przez cross-validation: \", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision mocno spadł natomiast, F1 trochę poszedł do góry, a wynik ROC-AUC praktycznie nie uległ zmianie. Ponieważ my i tak mamy jedynie 20 kolumn nie potrzebne jest usuwać kolejne kosztem utraty wyników, jednak gdyby oznaczało to znaczne zwiększenie efyktywności modelu można by się nad tym zastanowić"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.13      0.23      4321\n",
      "           1       0.04      0.96      0.08       179\n",
      "\n",
      "    accuracy                           0.16      4500\n",
      "   macro avg       0.52      0.55      0.16      4500\n",
      "weighted avg       0.95      0.16      0.22      4500\n",
      "\n",
      "Wynik ROC-AUC na zbiorze testowym:  0.7408324164564637\n",
      "Wynik ROC-AUC przez cross-validation:  0.7408062960736502\n",
      "Wynik F1 przez cross-validation:  0.08366627473079377\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_probs = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#Raport z wskaźnikami oceny modelu\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(\"Wynik ROC-AUC na zbiorze testowym: \", roc_auc_score(y_test, y_pred_probs))\n",
    "\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5, scoring=\"roc_auc\").mean()\n",
    "print(\"Wynik ROC-AUC przez cross-validation: \", scores)\n",
    "\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5, scoring=\"f1\").mean()\n",
    "print(\"Wynik F1 przez cross-validation: \", scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.24      0.39      4321\n",
      "           1       0.05      0.92      0.09       179\n",
      "\n",
      "    accuracy                           0.27      4500\n",
      "   macro avg       0.52      0.58      0.24      4500\n",
      "weighted avg       0.95      0.27      0.38      4500\n",
      "\n",
      "Wynik ROC-AUC na zbiorze testowym:  0.7567000965791336\n",
      "Wynik ROC-AUC przez cross-validation:  0.7443173831407464\n",
      "Wynik F1 przez cross-validation:  0.08985748530680153\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train_rfe, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_rfe)\n",
    "y_pred_probs = clf.predict_proba(X_test_rfe)[:, 1]\n",
    "\n",
    "#Raport z wskaźnikami oceny modelu\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Wynik ROC-AUC na zbiorze testowym: \", roc_auc_score(y_test, y_pred_probs))\n",
    "\n",
    "scores = cross_val_score(clf, X_train_rfe, y_train, cv=5, scoring=\"roc_auc\").mean()\n",
    "print(\"Wynik ROC-AUC przez cross-validation: \", scores)\n",
    "\n",
    "scores = cross_val_score(clf, X_train_rfe, y_train, cv=5, scoring=\"f1\").mean()\n",
    "print(\"Wynik F1 przez cross-validation: \", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaczynamy zauważać trend że wyniki na ramce po preprocessing RFE są w każdym modelu lepsze od base preprocessingu. Model NB ma trochę ROC od XGboost ale za to zdecydowanie wyższy F1. Wydaje się to narazie najlepsze połączenie dobrego wyniku F1 i ROC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spróbujemy zatem poprzez hiperparametry znaleźć najlepszą wartość parametru var_smoothing w celu otrzymana najlepszego wyniku F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=GaussianNB(var_smoothing=0.23101297000831597),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             scoring=&#x27;f1&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=GaussianNB(var_smoothing=0.23101297000831597),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             scoring=&#x27;f1&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB(var_smoothing=0.23101297000831597)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB(var_smoothing=0.23101297000831597)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GaussianNB(var_smoothing=0.23101297000831597),\n",
       "             param_grid={'var_smoothing': array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "\n",
    "gs_NB = GridSearchCV(estimator=clf, \n",
    "                     param_grid=params_NB, \n",
    "                     cv=5,\n",
    "                     verbose=1, \n",
    "                     scoring='f1')\n",
    "\n",
    "\n",
    "Data_transformed = PowerTransformer().fit_transform(X_train_rfe)\n",
    "gs_NB.fit(Data_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': 0.2848035868435802}\n",
      "0.25180493348414446\n"
     ]
    }
   ],
   "source": [
    "print(gs_NB.best_params_)\n",
    "print(gs_NB.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      4321\n",
      "           1       0.00      0.00      0.00       179\n",
      "\n",
      "    accuracy                           0.96      4500\n",
      "   macro avg       0.48      0.50      0.49      4500\n",
      "weighted avg       0.92      0.96      0.94      4500\n",
      "\n",
      "Wynik ROC-AUC na zbiorze testowym:  0.7826154973954663\n",
      "Wynik ROC-AUC przez cross-validation:  0.731134148056193\n",
      "Wynik F1 przez cross-validation:  0.25180493348414446\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB(**gs_NB.best_params_)\n",
    "X_train_transformed = PowerTransformer().fit_transform(X_train_rfe)\n",
    "X_test_transformed = PowerTransformer().fit_transform(X_test_rfe)\n",
    "\n",
    "clf.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_transformed)\n",
    "y_pred_probs = clf.predict_proba(X_test_transformed)[:, 1]\n",
    "\n",
    "#Raport z wskaźnikami oceny modelu\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Wynik ROC-AUC na zbiorze testowym: \", roc_auc_score(y_test, y_pred_probs))\n",
    "\n",
    "scores = cross_val_score(clf, X_train_transformed, y_train, cv=5, scoring=\"roc_auc\").mean()\n",
    "print(\"Wynik ROC-AUC przez cross-validation: \", scores)\n",
    "\n",
    "scores = cross_val_score(clf, X_train_transformed, y_train, cv=5, scoring=\"f1\").mean()\n",
    "print(\"Wynik F1 przez cross-validation: \", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yDKE-9O2QNc"
   },
   "source": [
    "#### Random Tree Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKgT47JRUvIs"
   },
   "source": [
    "#### Hiperparametry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do modelu random tree forest użujemy metody random search znajdowania hiperparametrów. Będziemy używać ramki X_train_rfe żeby znajdowanie nie trwało zbyt długo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNnermQPWQLN"
   },
   "source": [
    "Random Hyperparameter Grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DwE71IANU2zh"
   },
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 300, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 10)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1681938307861,
     "user": {
      "displayName": "Paweł Świderski",
      "userId": "16606458260379333856"
     },
     "user_tz": -120
    },
    "id": "tIuhNh_fVTrR",
    "outputId": "6a64e1c5-aa0d-492b-a0d7-c6640af41295"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [100, 122, 144, 166, 188, 211, 233, 255, 277, 300], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 21, 32, 43, 54, 65, 76, 87, 98, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap\n",
    "              }\n",
    "print(random_grid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Optymalizacja do ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=50,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [10, 21, 32, 43, 54, 65,\n",
       "                                                      76, 87, 98, 110, None],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 122, 144, 166,\n",
       "                                                         188, 211, 233, 255,\n",
       "                                                         277, 300]},\n",
       "                   random_state=42, scoring=&#x27;roc_auc&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=50,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [10, 21, 32, 43, 54, 65,\n",
       "                                                      76, 87, 98, 110, None],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 122, 144, 166,\n",
       "                                                         188, 211, 233, 255,\n",
       "                                                         277, 300]},\n",
       "                   random_state=42, scoring=&#x27;roc_auc&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=50,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 21, 32, 43, 54, 65,\n",
       "                                                      76, 87, 98, 110, None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 122, 144, 166,\n",
       "                                                         188, 211, 233, 255,\n",
       "                                                         277, 300]},\n",
       "                   random_state=42, scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 50, scoring = 'roc_auc', cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train_rfe, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': True}\n",
      "0.8201015282237034\n"
     ]
    }
   ],
   "source": [
    "print(rf_random.best_params_)\n",
    "print(rf_random.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      4321\n",
      "           1       0.00      0.00      0.00       179\n",
      "\n",
      "    accuracy                           0.96      4500\n",
      "   macro avg       0.48      0.50      0.49      4500\n",
      "weighted avg       0.92      0.96      0.94      4500\n",
      "\n",
      "Wynik ROC-AUC na zbiorze testowym:  0.8412624327857068\n",
      "Wynik ROC-AUC przez cross-validation:  0.8196437722579393\n",
      "Wynik F1 przez cross-validation:  0.0\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 300, min_samples_split = 10, min_samples_leaf = 2, max_features = 'sqrt', max_depth = 10, bootstrap = True)\n",
    "clf.fit(X_train_rfe, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_rfe)\n",
    "y_pred_probs = clf.predict_proba(X_test_rfe)[:, 1]\n",
    "\n",
    "\n",
    "#Raport z wskaźnikami oceny modelu\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Wynik ROC-AUC na zbiorze testowym: \", roc_auc_score(y_test, y_pred_probs))\n",
    "\n",
    "scores = cross_val_score(clf, X_train_rfe, y_train, cv=5, scoring=\"roc_auc\").mean()\n",
    "print(\"Wynik ROC-AUC przez cross-validation: \", scores)\n",
    "\n",
    "scores = cross_val_score(clf, X_train_rfe, y_train, cv=5, scoring=\"f1\").mean()\n",
    "print(\"Wynik F1 przez cross-validation: \", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wynik ROC-AUC jest dosyć wysoki jednak niewiele wyższy niż w XGBoost a za to znowu wróciliśmy do przewidywania samych 0 na zbiorze testowym oraz F1 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Optymalizacja do wyniku F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, error_score=&#x27;raise&#x27;,\n",
       "                   estimator=RandomForestClassifier(), n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [10, 21, 32, 43, 54, 65,\n",
       "                                                      76, 87, 98, 110, None],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 122, 144, 166,\n",
       "                                                         188, 211, 233, 255,\n",
       "                                                         277, 300]},\n",
       "                   random_state=42, scoring=&#x27;f1&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, error_score=&#x27;raise&#x27;,\n",
       "                   estimator=RandomForestClassifier(), n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [10, 21, 32, 43, 54, 65,\n",
       "                                                      76, 87, 98, 110, None],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 122, 144, 166,\n",
       "                                                         188, 211, 233, 255,\n",
       "                                                         277, 300]},\n",
       "                   random_state=42, scoring=&#x27;f1&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "                   estimator=RandomForestClassifier(), n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 21, 32, 43, 54, 65,\n",
       "                                                      76, 87, 98, 110, None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 122, 144, 166,\n",
       "                                                         188, 211, 233, 255,\n",
       "                                                         277, 300]},\n",
       "                   random_state=42, scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 50, scoring = 'f1', cv = 5, verbose=2, random_state=42, n_jobs = -1, error_score='raise')\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train_rfe, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 122, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 98, 'bootstrap': False}\n",
      "0.07327140362125067\n"
     ]
    }
   ],
   "source": [
    "print(rf_random.best_params_)\n",
    "print(rf_random.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      4321\n",
      "           1       0.17      0.04      0.06       179\n",
      "\n",
      "    accuracy                           0.95      4500\n",
      "   macro avg       0.57      0.52      0.52      4500\n",
      "weighted avg       0.93      0.95      0.94      4500\n",
      "\n",
      "Wynik ROC-AUC na zbiorze testowym:  0.7754800189796743\n",
      "Wynik ROC-AUC przez cross-validation:  0.753144928880608\n",
      "Wynik F1 przez cross-validation:  0.0698022819423614\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier( n_estimators = 122, min_samples_split = 2, min_samples_leaf = 1, max_features = 'sqrt', max_depth = 98, bootstrap = False)\n",
    "\n",
    "clf.fit(X_train_rfe, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_rfe)\n",
    "y_pred_probs = clf.predict_proba(X_test_rfe)[:, 1]\n",
    "\n",
    "\n",
    "#Raport z wskaźnikami oceny modelu\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Wynik ROC-AUC na zbiorze testowym: \", roc_auc_score(y_test, y_pred_probs))\n",
    "\n",
    "scores = cross_val_score(clf, X_train_rfe, y_train, cv=5, scoring=\"roc_auc\").mean()\n",
    "print(\"Wynik ROC-AUC przez cross-validation: \", scores)\n",
    "\n",
    "scores = cross_val_score(clf, X_train_rfe, y_train, cv=5, scoring=\"f1\").mean()\n",
    "print(\"Wynik F1 przez cross-validation: \", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widzimy metoda znajdowania hiperparametrów nie dała wyników lepszych niż Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naszym zdaniem najlepsze wyniki otrzymaliśmy z modelu Naive Bayes dla preprocessingu RFE"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1EoDMNdvU0lNpz1dxVm-wDbml5DlpvLiV",
     "timestamp": 1681968894718
    },
    {
     "file_id": "10SFcnHbgRzzi9t5VxY1UpmKjV5RrSUaH",
     "timestamp": 1681218957520
    },
    {
     "file_id": "108wSrIGslXS3LXopUoIZoaKy5Eioe6-e",
     "timestamp": 1680973076345
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
